# -*- coding: utf-8 -*-
"""dbt.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Gtvchxa2i5V9hE8BrkHdwgriz1BdvqzF
"""

from pendulum import datetime
from airflow import DAG
from airflow.operators.bash import BashOperator
from airflow.hooks.base import BaseHook

# Path to your dbt project
DBT_PROJECT_DIR = "/Users/divyathakar/Desktop/sjsu-data226/week8/airflow/dbt"

# Get Snowflake connection details
conn = BaseHook.get_connection('my_snowflake_conn')

# Define the DAG
with DAG(
    "BuildELT_dbt",
    start_date=datetime(2024, 10, 14),
    description="A sample Airflow DAG to invoke dbt runs using a BashOperator",
    schedule_interval=None,
    catchup=False,
) as dag:

    # Environment variables for dbt
    dbt_env = {
        "DBT_USER": conn.login,
        "DBT_PASSWORD": conn.password,
        "DBT_ACCOUNT": conn.extra_dejson.get("account"),
        "DBT_SCHEMA": conn.extra_dejson.get("schema"),
        "DBT_DATABASE": conn.extra_dejson.get("database"),
        "DBT_ROLE": conn.extra_dejson.get("role"),
        "DBT_WAREHOUSE": conn.extra_dejson.get("warehouse"),
        "DBT_TYPE": "snowflake",
    }

    # Task: dbt run
    dbt_run = BashOperator(
        task_id="dbt_run",
        bash_command=f"dbt run --profiles-dir {DBT_PROJECT_DIR} --project-dir {DBT_PROJECT_DIR}",
        env=dbt_env,
    )

    # Task: dbt test
    dbt_test = BashOperator(
        task_id="dbt_test",
        bash_command=f"dbt test --profiles-dir {DBT_PROJECT_DIR} --project-dir {DBT_PROJECT_DIR}",
        env=dbt_env,
    )

    # Task: dbt snapshot
    dbt_snapshot = BashOperator(
        task_id="dbt_snapshot",
        bash_command=f"dbt snapshot --profiles-dir {DBT_PROJECT_DIR} --project-dir {DBT_PROJECT_DIR}",
        env=dbt_env,
    )

    # Task dependencies
    dbt_run >> dbt_test >> dbt_snapshot